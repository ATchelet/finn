{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5420d782",
   "metadata": {},
   "source": [
    "Small Test Net - Alon Tchelet MSc Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a1db6",
   "metadata": {},
   "source": [
    "# Brevitas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726a95b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36887421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general use libraries\n",
    "import numpy as np\n",
    "\n",
    "# Brevitaas ad PyTorch libraries\n",
    "import torch\n",
    "from torch.nn import Module, ModuleList, Sequential, Conv2d, Linear, ReLU, MaxPool2d, Flatten\n",
    "from brevitas.nn import QuantIdentity, QuantConv2d, QuantLinear, QuantReLU, QuantMaxPool2d\n",
    "from brevitas.inject.defaults import *\n",
    "from brevitas.inject import *\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.bit_width import BitWidthImplType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "from brevitas.core.restrict_val import FloatToIntImplType\n",
    "from brevitas.quant.solver import WeightQuantSolver, ActQuantSolver\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.zero_point import ZeroZeroPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da1024",
   "metadata": {},
   "source": [
    "## Set up network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec3b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyQuant(ExtendedInjector):\n",
    "    bit_width_impl_type = BitWidthImplType.CONST\n",
    "    scaling_impl_type = ScalingImplType.CONST\n",
    "    float_to_int_impl_type = FloatToIntImplType.ROUND\n",
    "    restrict_scaling_type = RestrictValueType.FP\n",
    "    zero_point_impl = ZeroZeroPoint\n",
    "    narrow_range = True\n",
    "    quant_delay_steps = 50\n",
    "    \n",
    "    @value\n",
    "    def quant_type(bit_width):\n",
    "        if bit_width == 1:\n",
    "            return QuantType.BINARY\n",
    "        else:\n",
    "            return QuantType.INT   \n",
    "\n",
    "class MyActQuant(MyQuant, ActQuantSolver):\n",
    "    min_val = 0.0\n",
    "    max_val = 6.0\n",
    "    signed = False \n",
    "    \n",
    "class MyWeightQuant(MyQuant, WeightQuantSolver):\n",
    "    scaling_const = 0.1\n",
    "    signed = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e46664",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLeNet(Module):\n",
    "\n",
    "    # init for CIFAR-10\n",
    "    def __init__(self, weight_bit_width=8, act_bit_width=8):\n",
    "        super(QLeNet, self).__init__()\n",
    "        self.weight_bit_width = int(np.clip(weight_bit_width, 1, 8))\n",
    "        self.act_bit_width = int(np.clip(act_bit_width, 1, 8))\n",
    "\n",
    "        self.conv1 = Sequential(\n",
    "            QuantIdentity(\n",
    "            act_quant=Int8ActPerTensorFloatMinMaxInit,\n",
    "            min_val = -1.0,\n",
    "            max_val = 1.0 - 2.0 ** (-7),\n",
    "            signed = True,\n",
    "            restrict_scaling_type=RestrictValueType.POWER_OF_TWO),\n",
    "            QuantConv2d(3, 6, 5, bias=False, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(bit_width=self.act_bit_width),\n",
    "            QuantMaxPool2d(2, 2))\n",
    "        self.conv2 = Sequential(\n",
    "            QuantConv2d(6, 16, 5, bias=False, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(bit_width=self.act_bit_width),\n",
    "            QuantMaxPool2d(2, 2))\n",
    "        self.flat = Flatten()\n",
    "        self.fc1 = Sequential(\n",
    "            QuantLinear(400, 120, bias=True, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(bit_width=self.act_bit_width))\n",
    "        self.fc2 = Sequential(\n",
    "            QuantLinear(120, 84, bias=True, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(bit_width=self.act_bit_width))\n",
    "        self.fc3 = QuantLinear(84, 10, bias=False, weight_bit_width=self.weight_bit_width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1b1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "        # init for CIFAR-10\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = Sequential(\n",
    "            Conv2d(3, 6, 5),\n",
    "            ReLU(),\n",
    "            MaxPool2d(2, 2))\n",
    "        self.conv2 = Sequential(\n",
    "            Conv2d(6, 16, 5),\n",
    "            ReLU(),\n",
    "            MaxPool2d(2, 2))\n",
    "        self.flat = Flatten()\n",
    "        self.fc1 = Sequential(\n",
    "            Linear(400, 120),\n",
    "            ReLU())\n",
    "        self.fc2 = Sequential(\n",
    "            Linear(120, 84),\n",
    "            ReLU())\n",
    "        self.fc3 = Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenets = []\n",
    "lenets_names = []\n",
    "\n",
    "# for i in range(2, 9):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i, act_bit_width=i))\n",
    "#     lenets_names.append(f\"lenet_w{i}a{i}\")\n",
    "    \n",
    "# for i in range(2, 8):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i+1, act_bit_width=i))\n",
    "#     lenets_names.append(f\"lenet_w{i+1}a{i}\")\n",
    "\n",
    "# for i in range(1, 8):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i, act_bit_width=i+1))\n",
    "#     lenets_names.append(f\"lenet_w{i}a{i+1}\")\n",
    "    \n",
    "# for i in range(2, 7):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i+2, act_bit_width=i))\n",
    "#     lenets_names.append(f\"lenet_w{i+2}a{i}\")\n",
    "\n",
    "# for i in range(1, 7):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i, act_bit_width=i+2))\n",
    "#     lenets_names.append(f\"lenet_w{i}a{i+2}\")\n",
    "\n",
    "lenet_w3a4 = QLeNet(weight_bit_width=3, act_bit_width=4)\n",
    "lenets.append(lenet_w3a4)\n",
    "lenets_names.append(\"lenet_w3a4\")\n",
    "# lenet_w4a3 = QLeNet(weight_bit_width=4, act_bit_width=3)\n",
    "# lenets.append(lenet_w4a3)\n",
    "# lenets_names.append(\"lenet_w4a3\")\n",
    "# lenet_w2a4 = QLeNet(weight_bit_width=2, act_bit_width=4)\n",
    "# lenets.append(lenet_w2a4)\n",
    "# lenets_names.append(\"lenet_w2a4\")\n",
    "# lenet_w2a3 = QLeNet(weight_bit_width=2, act_bit_width=3)\n",
    "# lenets.append(lenet_w2a3)\n",
    "# lenets_names.append(\"lenet_w2a3\")\n",
    "\n",
    "# lenets.append(LeNet())\n",
    "# lenets_names.append(\"lenet_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741da6b5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a4d3a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import SubsetRandomSampler as Sampler\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32\n",
    "split = .9\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                        download=True, transform=transform)\n",
    "validset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "train_len = len(trainset)\n",
    "split = int(split*train_len)\n",
    "idx = list(range(train_len))\n",
    "train_idx, valid_idx = idx[split:], idx[:split]\n",
    "train_samples = Sampler(train_idx)\n",
    "valid_samples = Sampler(valid_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                           sampler=train_samples, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
    "                                          sampler=valid_samples, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e6e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizers = []\n",
    "lr = 0.001\n",
    "epochs = 13\n",
    "\n",
    "for net in lenets:\n",
    "    optimizers.append(optim.Adam(net.parameters(), lr=lr, weight_decay=0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f67922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training for net: lenet_w3a4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] training loss: 2.037854 - valid loss: 1.882289\n",
      "[Epoch: 2] training loss: 1.805160 - valid loss: 1.774926\n",
      "[Epoch: 3] training loss: 1.678211 - valid loss: 1.694100\n",
      "[Epoch: 4] training loss: 1.592391 - valid loss: 1.599484\n",
      "[Epoch: 5] training loss: 1.522920 - valid loss: 1.606223\n",
      "[Epoch: 6] training loss: 1.486556 - valid loss: 1.568794\n",
      "[Epoch: 7] training loss: 1.428077 - valid loss: 1.557950\n",
      "[Epoch: 8] training loss: 1.363779 - valid loss: 1.522115\n",
      "[Epoch: 9] training loss: 1.325628 - valid loss: 1.534006\n",
      "[Epoch: 10] training loss: 1.266249 - valid loss: 1.489083\n",
      "[Epoch: 11] training loss: 1.199435 - valid loss: 1.480788\n",
      "[Epoch: 12] training loss: 1.159517 - valid loss: 1.561427\n",
      "[Epoch: 13] training loss: 1.133013 - valid loss: 1.595522\n",
      "Finished training for net: lenet_w3a4\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for n, net in enumerate(lenets):\n",
    "    print(f\"Started training for net: {lenets_names[n]}\")\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        train_loss = valid_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizers[n].zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizers[n].step()\n",
    "\n",
    "            # print statistics\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= i\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                images, labels = data\n",
    "                outputs = net(images)\n",
    "                vloss = criterion(outputs, labels)\n",
    "                valid_loss += vloss.item()\n",
    "            valid_loss /= i\n",
    "        print(f\"[Epoch: {epoch+1}] training loss: {train_loss:.6f} - valid loss: {valid_loss:.6f}\")\n",
    "        train_loss = valid_loss = 0.0\n",
    "        \n",
    "#         correct = 0\n",
    "#         top3 = 0\n",
    "#         top5 = 0\n",
    "#         total = 0\n",
    "#         with torch.no_grad():\n",
    "#             for data in testloader:\n",
    "#                 images, labels = data\n",
    "#                 outputs = net(images)\n",
    "#                 _, predicted = torch.max(outputs.data, 1)\n",
    "#                 top3_outputs = torch.argsort(outputs.data, 1)[:, -3:]\n",
    "#                 top5_outputs = torch.argsort(outputs.data, 1)[:, -5:]\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "#                 top3 += sum([(out==labels[i]).sum() for i, out in enumerate(top3_outputs)])\n",
    "#                 top5 += sum([(out==labels[i]).sum() for i, out in enumerate(top5_outputs)])\n",
    "#         print(f\"[Epoch: {epoch+1}] Network Accuracy:\\tTop-1: {100 * correct / total : .2f},\\tTop-3: {100 * top3 / total : .2f},\\tTop-5: {100 * top5 / total : .2f}\")\n",
    "            \n",
    "    print(f\"Finished training for net: {lenets_names[n]}\\n\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af6b585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save network\n",
    "for n, net in enumerate(lenets):\n",
    "    path = f\"./{lenets_names[n]}.pth\"\n",
    "    torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4bc72",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d37e65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001,\tBatch size: 32,\tIterations: 13\n",
      "lenet_w3a4 Network Accuracy:\tTop-1:  10.88,\tTop-3:  29.58,\tTop-5:  50.14\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# if you need to load the networks\n",
    "#\n",
    "# lenet_og = QLeNet()\n",
    "# lenet_w8 = QLeNet(weight_bit_width=8)\n",
    "# lenet_w4 = QLeNet(weight_bit_width=4)\n",
    "# lenet_w2 = QLeNet(weight_bit_width=2)\n",
    "# lenet_w8a8 = QLeNet(weight_bit_width=8, act_bit_width=8)\n",
    "# lenet_w4a4 = QLeNet(weight_bit_width=4, act_bit_width=4)\n",
    "# lenet_w2a2 = QLeNet(weight_bit_width=2, act_bit_width=2)\n",
    "# lenets = [lenet_w8a8, lenet_w4a4, lenet_w2a2, lenet_w8, lenet_w4, lenet_w2, lenet_og]\n",
    "# lenets_names = [\"lenet_w8a8\", \"lenet_w4a4\", \"lenet_w2a2\", \"lenet_w8\", \"lenet_w4\", \"lenet_w2\", \"lenet_og\"]\n",
    "# for n, net in enumerate(lenets):\n",
    "#     path = f'./{lenets_names[n]}.pth'\n",
    "#     net.load_state_dict(torch.load(path))\n",
    "#\n",
    "\n",
    "print(f\"Learning rate: {lr},\\tBatch size: {batch_size},\\tIterations: {epochs}\")\n",
    "for n, net in enumerate(lenets):    \n",
    "    correct = 0\n",
    "    top3 = 0\n",
    "    top5 = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            top3_outputs = torch.argsort(outputs.data, 1)[:, -3:]\n",
    "            top5_outputs = torch.argsort(outputs.data, 1)[:, -5:]\n",
    "#             print(f'Predicted: {predicted} - Labels: {labels}\\n')\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            top3 += sum([(out==labels[i]).sum() for i, out in enumerate(top3_outputs)])\n",
    "            top5 += sum([(out==labels[i]).sum() for i, out in enumerate(top5_outputs)])\n",
    "    print(f\"{lenets_names[n]} Network Accuracy:\\tTop-1: {100 * correct / total : .2f},\\tTop-3: {100 * top3 / total : .2f},\\tTop-5: {100 * top5 / total : .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf0f617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenets = []\n",
    "lenets_names = []\n",
    "\n",
    "lenet_w3a4 = QLeNet(weight_bit_width=3, act_bit_width=4)\n",
    "lenets.append(lenet_w3a4)\n",
    "lenets_names.append(\"lenet_w3a4\")\n",
    "# lenet_w4a3 = QLeNet(weight_bit_width=4, act_bit_width=3)\n",
    "# lenets.append(lenet_w4a3)\n",
    "# lenets_names.append(\"lenet_w4a3\")\n",
    "# lenet_w2a4 = QLeNet(weight_bit_width=2, act_bit_width=4)\n",
    "# lenets.append(lenet_w2a4)\n",
    "# lenets_names.append(\"lenet_w2a4\")\n",
    "# lenet_w2a3 = QLeNet(weight_bit_width=2, act_bit_width=3)\n",
    "# lenets.append(lenet_w2a3)\n",
    "# lenets_names.append(\"lenet_w2a3\")\n",
    "\n",
    "# lenets.append(LeNet())\n",
    "# lenets_names.append(\"lenet_base\")\n",
    "\n",
    "for n, net in enumerate(lenets):\n",
    "    path = f'./{lenets_names[n]}.pth'\n",
    "    net.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f90930",
   "metadata": {},
   "source": [
    "# FINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e3506e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b23d4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINN-Brevitas imports\n",
    "from brevitas.export.onnx.generic.manager import BrevitasONNXManager\n",
    "\n",
    "\n",
    "# ONNX libraries\n",
    "import onnx\n",
    "import onnx.numpy_helper as nph\n",
    "import onnxruntime as rt\n",
    "\n",
    "# Network display methods - Netron\n",
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "# FINN Network Preperation imports\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from qonnx.util.cleanup import cleanup_model\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from finn.transformation.general import GiveUniqueNodeNames\n",
    "from finn.util.pytorch import ToTensor\n",
    "from finn.transformation.merge_onnx_models import MergeONNXModels\n",
    "from finn.core.datatype import DataType\n",
    "from finn.transformation.insert_topk import InsertTopK\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "from finn.transformation.general import RemoveUnusedTensors\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import CreateDataflowPartition\n",
    "from finn.custom_op.registry import getCustomOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268e877",
   "metadata": {},
   "source": [
    "## Brevitas Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca1e2f78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting lenet_w3a4\n"
     ]
    }
   ],
   "source": [
    "for n, net in enumerate(lenets):\n",
    "    print(f\"exporting {lenets_names[n]}\")\n",
    "    onnx_export_path = f\"./onnx/{lenets_names[n]}.onnx\"\n",
    "    BrevitasONNXManager.export(net, (1, 3, 32, 32), onnx_export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f54c59",
   "metadata": {},
   "source": [
    "## Network Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfadd0a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# select which network to work with\n",
    "net_n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40dd984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './onnx/lenet_w3a4.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "toDisplay = True\n",
    "# display net through Netron\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990164f",
   "metadata": {},
   "source": [
    "### Tidy ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ec254f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}.onnx\")\n",
    "model = cleanup_model(model)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_tidy.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caedc379",
   "metadata": {},
   "source": [
    "### Add Pre/Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d325dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn-base/src/finn/transformation/infer_data_layouts.py:119: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_pre_post.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_tidy.onnx\")\n",
    "\n",
    "# pre-processing\n",
    "in_name = model.graph.input[0].name\n",
    "in_shape = model.get_tensor_shape(in_name)\n",
    "totensor = ToTensor()\n",
    "BrevitasONNXManager.export(totensor, in_shape, f\"./onnx/{lenets_names[net_n]}_pre.onnx\")\n",
    "pre_model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_pre.onnx\")\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "in_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(in_name, DataType[\"UINT8\"])\n",
    "\n",
    "# post-processing\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "model = cleanup_model(model)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_pre_post.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_pre_post.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c0be1",
   "metadata": {},
   "source": [
    "### Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01258d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_streamline.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_pre_post.onnx\")\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "# model = model.transform(absorb.AbsorbTransposeIntoFlatten())\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_streamline.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_streamline.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed0d00",
   "metadata": {},
   "source": [
    "### convert to HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07b8c6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_hls.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_streamline.onnx\")\n",
    "model = model.transform(to_hls.InferQuantizedStreamingFCLayer())\n",
    "model = model.transform(to_hls.InferThresholdingLayer())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(to_hls.InferConvInpGen())\n",
    "model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(to_hls.InferLabelSelectLayer())\n",
    "model = model.transform(InferDataLayouts())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_hls.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_hls.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6dc7f7",
   "metadata": {},
   "source": [
    "### Create Dataflow Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffe9812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_dataflow_parent.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_hls.onnx\")\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(f\"./onnx/{lenets_names[net_n]}_dataflow_parent.onnx\")\n",
    "\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_dataflow_parent.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8b26034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "parent_model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_dataflow_parent.onnx\")\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "dataflow_model.save(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")\n",
    "\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fcde36",
   "metadata": {},
   "source": [
    "### Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02a59a5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomOp wrapper is of class StreamingFCLayer_Batch #1\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 75\n",
      "MH: ('i', True, 0) = 6\n",
      "resType: ('s', False, 'lut', {'auto', 'lut', 'dsp'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = INT8\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT16\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1, 28, 28]\n",
      "mem_mode: ('s', False, 'const', {'decoupled', 'external', 'const'}) = const\n",
      "ram_style: ('s', False, 'auto', {'distributed', 'auto', 'ultra', 'block'}) = auto\n",
      "ram_style_thresholds: ('s', False, 'auto', {'distributed', 'auto', 'block'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'cppsim', 'rtlsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #2\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 150\n",
      "MH: ('i', True, 0) = 16\n",
      "resType: ('s', False, 'lut', {'auto', 'lut', 'dsp'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT14\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1, 10, 10]\n",
      "mem_mode: ('s', False, 'const', {'decoupled', 'external', 'const'}) = const\n",
      "ram_style: ('s', False, 'auto', {'distributed', 'auto', 'ultra', 'block'}) = auto\n",
      "ram_style_thresholds: ('s', False, 'auto', {'distributed', 'auto', 'block'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'cppsim', 'rtlsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #3\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 400\n",
      "MH: ('i', True, 0) = 120\n",
      "resType: ('s', False, 'lut', {'auto', 'lut', 'dsp'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT16\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1]\n",
      "mem_mode: ('s', False, 'const', {'decoupled', 'external', 'const'}) = const\n",
      "ram_style: ('s', False, 'auto', {'distributed', 'auto', 'ultra', 'block'}) = auto\n",
      "ram_style_thresholds: ('s', False, 'auto', {'distributed', 'auto', 'block'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'cppsim', 'rtlsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #4\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 120\n",
      "MH: ('i', True, 0) = 84\n",
      "resType: ('s', False, 'lut', {'auto', 'lut', 'dsp'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT14\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1]\n",
      "mem_mode: ('s', False, 'const', {'decoupled', 'external', 'const'}) = const\n",
      "ram_style: ('s', False, 'auto', {'distributed', 'auto', 'ultra', 'block'}) = auto\n",
      "ram_style_thresholds: ('s', False, 'auto', {'distributed', 'auto', 'block'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'cppsim', 'rtlsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #5\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 84\n",
      "MH: ('i', True, 0) = 10\n",
      "resType: ('s', False, 'lut', {'auto', 'lut', 'dsp'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = INT16\n",
      "accDataType: ('s', False, 'INT32') = INT16\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 1\n",
      "numInputVectors: ('ints', False, [1]) = [1]\n",
      "mem_mode: ('s', False, 'const', {'decoupled', 'external', 'const'}) = const\n",
      "ram_style: ('s', False, 'auto', {'distributed', 'auto', 'ultra', 'block'}) = auto\n",
      "ram_style_thresholds: ('s', False, 'auto', {'distributed', 'auto', 'block'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'cppsim', 'rtlsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")\n",
    "layers = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")\n",
    "# fc0w = getCustomOp(fc0)\n",
    "# print(\"CustomOp wrapper is of class \" + fc0w.__class__.__name__)\n",
    "for i, layer in enumerate(layers):\n",
    "    temp_op = getCustomOp(layer)\n",
    "    print(f\"CustomOp wrapper is of class StreamingFCLayer_Batch #{i+1}\")\n",
    "    for item in temp_op.get_nodeattr_types():\n",
    "        print(f\"{item}: {temp_op.get_nodeattr_types()[item]} = {temp_op.get_nodeattr(item)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "303225b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_folded.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")\n",
    "\n",
    "# set convolution-input (sliding window) layers folding factors\n",
    "sw_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator\")\n",
    "sw_folding = [3, \n",
    "              2]\n",
    "for layer, simd in zip(sw_layers, sw_folding):\n",
    "    fcl_inst = getCustomOp(layer)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    \n",
    "# set fully-connected layers folding factors\n",
    "fc_layers = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")\n",
    "fc_folding = [\n",
    "    (1, 3),\n",
    "    (2, 2),\n",
    "    (1, 4),\n",
    "    (1, 1),\n",
    "    (1, 1)\n",
    "]\n",
    "for layer, (pe, simd) in zip(fc_layers, fc_folding):\n",
    "    fcl_inst = getCustomOp(layer)\n",
    "    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    \n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_folded.onnx\")\n",
    "\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_folded.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df781a4c",
   "metadata": {},
   "source": [
    "## Hardware Build and Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d59e91",
   "metadata": {},
   "source": [
    "### Hardware Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a68c809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/transformation/fpgadataflow/floorplan.py:107: UserWarning: 18 nodes have no entry in the provided floorplan, SLR was set to -1\n",
      "  warnings.warn(\n",
      "/workspace/finn/src/finn/transformation/fpgadataflow/insert_fifo.py:154: UserWarning: Overriding input FIFO depth to 32\n",
      "  warnings.warn(\"Overriding input FIFO depth to 32\")\n",
      "/workspace/finn/src/finn/transformation/fpgadataflow/insert_fifo.py:201: UserWarning: Overriding output FIFO depth to 32\n",
      "  warnings.warn(\"Overriding output FIFO depth to 32\")\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "IPGen failed: /tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36/project_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3/sol1/impl/ip not found. Check log under /tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/workspace/finn/src/finn/transformation/fpgadataflow/hlssynth_ip.py\", line 69, in applyNodeLocal\n    inst.ipgen_singlenode_code()\n  File \"/workspace/finn/src/finn/custom_op/fpgadataflow/hlscustomop.py\", line 328, in ipgen_singlenode_code\n    assert os.path.isdir(\nAssertionError: IPGen failed: /tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36/project_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3/sol1/impl/ip not found. Check log under /tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4479c923428e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./onnx/{lenets_names[net_n]}_folded.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZynqBuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ZCU102\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./onnx/{lenets_names[net_n]}_hw.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/core/modelwrapper.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, transformation, make_deepcopy, cleanup, fix_float64)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mmodel_was_changed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mmodel_was_changed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             (transformed_model, model_was_changed) = transformation.apply(\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0mtransformed_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             )\n",
      "\u001b[0;32m/workspace/finn/src/finn/transformation/fpgadataflow/make_zynq_proj.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mPrepareIP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpga_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             )\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0mkernel_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHLSSynthIP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m             kernel_model = kernel_model.transform(\n\u001b[1;32m    349\u001b[0m                 CreateStitchedIP(\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/core/modelwrapper.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, transformation, make_deepcopy, cleanup, fix_float64)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mmodel_was_changed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mmodel_was_changed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             (transformed_model, model_was_changed) = transformation.apply(\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0mtransformed_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             )\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/transformation/base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# Execute transformation in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mnew_nodes_and_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplyNodeLocal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# extract nodes and check if the transformation needs to run again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: IPGen failed: /tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36/project_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3/sol1/impl/ip not found. Check log under /tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "\n",
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_folded.onnx\")\n",
    "model = model.transform(ZynqBuild(platform = \"ZCU102\", period_ns = 10))\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_hw.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85baa04e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2020.1 (64-bit)\n",
      "  **** SW Build 2902540 on Wed May 27 19:54:35 MDT 2020\n",
      "  **** IP Build 2902112 on Wed May 27 22:43:36 MDT 2020\n",
      "    ** Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /tools/Xilinx/Vivado/2020.1/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: [HLS 200-10] Running '/tools/Xilinx/Vivado/2020.1/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "/tools/Xilinx/Vivado/2020.1/tps/tcl/tcl8.5/tzdata/Europe/Dublin can't be opened.\n",
      "INFO: [HLS 200-10] For user '' on host 'finn_dev_atchelet' (Linux_x86_64 version 5.4.0-91-generic) on Fri Jan 07 15:56:12 +0000 2022\n",
      "INFO: [HLS 200-10] On os Ubuntu 18.04.6 LTS\n",
      "INFO: [HLS 200-10] In directory '/tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36'\n",
      "Sourcing Tcl script '/tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36/hls_syn_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3.tcl'\n",
      "HLS project: project_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3\n",
      "HW source dir: /tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36\n",
      "INFO: [HLS 200-10] Creating and opening project '/tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36/project_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3'.\n",
      "INFO: [HLS 200-10] Adding design file '/tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36/top_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3.cpp' to the project\n",
      "INFO: [HLS 200-10] Creating and opening solution '/tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36/project_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3/sol1'.\n",
      "INFO: [HLS 200-10] Setting target device to 'xczu9eg-ffvb1156-2-e'\n",
      "WARNING: [XFORM 203-506] Disable code size check when do loop unroll.\n",
      "WARNING: [ANALYSIS 214-1] Skip long-run-time warning caused by lots of load/store instructions.\n",
      "WARNING: [HLS 200-483] The 'config_rtl -auto_prefix' command is deprecated and will be removed in a future release. Use 'config_rtl -module_auto_prefix' as its replacement.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file '/tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36/top_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3.cpp' ... \n",
      "INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:52 ; elapsed = 00:00:58 . Memory (MB): peak = 1657.262 ; gain = 1227.754 ; free physical = 1426 ; free virtual = 9096\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:52 ; elapsed = 00:00:58 . Memory (MB): peak = 1657.262 ; gain = 1227.754 ; free physical = 1426 ; free virtual = 9096\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-3.1' (/workspace/finn-hlslib/mvau.hpp:138) in function 'void Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>(hls::stream<FORWARD_REFERENCE, 0>&, hls::stream<FORWARD_REFERENCE, 0>&, FORWARD_REFERENCE const&, FORWARD_REFERENCE const&, int, FORWARD_REFERENCE const&)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-3.1.1' (/workspace/finn-hlslib/mvau.hpp:140) in function 'void Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>(hls::stream<FORWARD_REFERENCE, 0>&, hls::stream<FORWARD_REFERENCE, 0>&, FORWARD_REFERENCE const&, FORWARD_REFERENCE const&, int, FORWARD_REFERENCE const&)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-3.2' (/workspace/finn-hlslib/mvau.hpp:149) in function 'void Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>(hls::stream<FORWARD_REFERENCE, 0>&, hls::stream<FORWARD_REFERENCE, 0>&, FORWARD_REFERENCE const&, FORWARD_REFERENCE const&, int, FORWARD_REFERENCE const&)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-3.3' (/workspace/finn-hlslib/mvau.hpp:163) in function 'void Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>(hls::stream<FORWARD_REFERENCE, 0>&, hls::stream<FORWARD_REFERENCE, 0>&, FORWARD_REFERENCE const&, FORWARD_REFERENCE const&, int, FORWARD_REFERENCE const&)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-3.3.1' (/workspace/finn-hlslib/mvau.hpp:165) in function 'void Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>(hls::stream<FORWARD_REFERENCE, 0>&, hls::stream<FORWARD_REFERENCE, 0>&, FORWARD_REFERENCE const&, FORWARD_REFERENCE const&, int, FORWARD_REFERENCE const&)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (/workspace/finn-hlslib/weights.hpp:134) in function 'FixedPointWeights<1u, ap_int<3>, 1u, 10080u>::TileIndex::operator[](unsigned int) const' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (/workspace/finn-hlslib/mac.hpp:167) in function 'FORWARD_REFERENCE mac<1u, ap_int<14>, std::array<ap_int<3>, 1ul>, Slice<ap_uint<4>, 4u>::Container<ap_uint<4> >, ap_resource_lut>(FORWARD_REFERENCE const&, FORWARD_REFERENCE const&, FORWARD_REFERENCE const&, FORWARD_REFERENCE const&, unsigned int)' completely with a factor of 1.\n",
      "INFO: [XFORM 203-603] Inlining function 'WidthAdjustedInputStream<4u, 4u, 120u>::operator hls::stream<ap_uint<4>, 0>&' into 'StreamingFCLayer_Batch<120u, 84u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, 4, 4, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/fclayer.h:108).\n",
      "INFO: [XFORM 203-603] Inlining function 'WidthAdjustedOutputStream<4u, 4u, 84u>::operator hls::stream<ap_uint<4>, 0>&' into 'StreamingFCLayer_Batch<120u, 84u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, 4, 4, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/fclayer.h:109).\n",
      "INFO: [XFORM 203-603] Inlining function 'ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >::init' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/mvau.hpp:142).\n",
      "INFO: [XFORM 203-603] Inlining function 'FixedPointWeights<1u, ap_int<3>, 1u, 10080u>::weights' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/mvau.hpp:148).\n",
      "INFO: [XFORM 203-603] Inlining function 'std::array<ap_int<3>, 1ul>::operator[].1' into 'FixedPointWeights<1u, ap_int<3>, 1u, 10080u>::TileIndex::operator[]' (/workspace/finn-hlslib/weights.hpp:139).\n",
      "INFO: [XFORM 203-603] Inlining function 'FixedPointWeights<1u, ap_int<3>, 1u, 10080u>::TileIndex::operator[]' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/mvau.hpp:151).\n",
      "INFO: [XFORM 203-603] Inlining function 'Identity::operator()<std::array<ap_int<3>, 1ul> >' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/mvau.hpp:151).\n",
      "INFO: [XFORM 203-603] Inlining function 'Slice<ap_uint<4>, 4u>::operator()<ap_uint<4> >' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/mvau.hpp:153).\n",
      "INFO: [XFORM 203-603] Inlining function 'std::array<ap_int<3>, 1ul>::operator[]' into 'mac<1u, ap_int<14>, std::array<ap_int<3>, 1ul>, Slice<ap_uint<4>, 4u>::Container<ap_uint<4> >, ap_resource_lut>' (/workspace/finn-hlslib/mac.hpp:169).\n",
      "INFO: [XFORM 203-603] Inlining function 'Slice<ap_uint<4>, 4u>::Container<ap_uint<4> >::operator().1' into 'mac<1u, ap_int<14>, std::array<ap_int<3>, 1ul>, Slice<ap_uint<4>, 4u>::Container<ap_uint<4> >, ap_resource_lut>' (/workspace/finn-hlslib/mac.hpp:169).\n",
      "INFO: [XFORM 203-603] Inlining function 'mul<ap_int<3>, ap_uint<4> >' into 'mac<1u, ap_int<14>, std::array<ap_int<3>, 1ul>, Slice<ap_uint<4>, 4u>::Container<ap_uint<4> >, ap_resource_lut>' (/workspace/finn-hlslib/mac.hpp:169).\n",
      "INFO: [XFORM 203-603] Inlining function 'mac<1u, ap_int<14>, std::array<ap_int<3>, 1ul>, Slice<ap_uint<4>, 4u>::Container<ap_uint<4> >, ap_resource_lut>' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/mvau.hpp:154).\n",
      "INFO: [XFORM 203-603] Inlining function 'Slice<ap_uint<4>, 4u>::operator()<ap_uint<4> >.1' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/mvau.hpp:162).\n",
      "INFO: [XFORM 203-603] Inlining function 'Slice<ap_uint<4>, 4u>::Container<ap_uint<4> >::operator()' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/mvau.hpp:167).\n",
      "INFO: [XFORM 203-603] Inlining function 'ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >::activate' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/mvau.hpp:167).\n",
      "INFO: [XFORM 203-603] Inlining function 'Slice<ap_uint<4>, 4u>::Container<ap_uint<4> >::operator ap_uint<4> const&' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/mvau.hpp:170).\n",
      "INFO: [XFORM 203-603] Inlining function 'StreamingFCLayer_Batch<120u, 84u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, 4, 4, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' into 'StreamingDataflowPartition_1_StreamingFCLayer_Batch_3' (/tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36/top_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3.cpp:35).\n",
      "INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:35:07 ; elapsed = 00:35:14 . Memory (MB): peak = 1657.262 ; gain = 1227.754 ; free physical = 1831 ; free virtual = 9674\n",
      "INFO: [HLS 200-10] Checking synthesizability ...\n",
      "INFO: [XFORM 203-602] Inlining function 'Caster<ap_uint<4> >::cast<4>' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/interpret.hpp:216->/workspace/finn-hlslib/mac.hpp:169->/workspace/finn-hlslib/mvau.hpp:154) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'comp::less_equal<ap_int<14> >::operator()' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/activations.hpp:186->/workspace/finn-hlslib/mvau.hpp:167) automatically.\n",
      "INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:38:57 ; elapsed = 00:39:04 . Memory (MB): peak = 1657.262 ; gain = 1227.754 ; free physical = 1891 ; free virtual = 9731\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Loop-1' (/workspace/finn-hlslib/mvau.hpp:122) in function 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' for pipelining.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (/workspace/finn-hlslib/activations.hpp:184) in function 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' completely with a factor of 15.\n",
      "INFO: [XFORM 203-101] Partitioning array 'weights.m_weights.V' (/tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36/params.h:1) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'threshs.m_thresholds.V'  in dimension 1 completely.\n",
      "WARNING: [XFORM 203-104] Completely partitioning array 'inputBuf.V' (/workspace/finn-hlslib/mvau.hpp:108) accessed through non-constant indices on dimension 1 (/workspace/finn-hlslib/mvau.hpp:129:7), which may result in long runtime and suboptimal QoR due to large multiplexers. Please consider wrapping the array access into a function or using a register file core instead.\n",
      "INFO: [XFORM 203-101] Partitioning array 'inputBuf.V' (/workspace/finn-hlslib/mvau.hpp:108) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'accu.V' (/workspace/finn-hlslib/mvau.hpp:112) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'threshs.m_thresholds.V'  in dimension 3 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'accu.V' (/workspace/finn-hlslib/mvau.hpp:112) in dimension 2 completely.\n",
      "INFO: [XFORM 203-602] Inlining function 'Caster<ap_uint<4> >::cast<4>' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/interpret.hpp:216->/workspace/finn-hlslib/mac.hpp:169->/workspace/finn-hlslib/mvau.hpp:154) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'comp::less_equal<ap_int<14> >::operator()' into 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/activations.hpp:186->/workspace/finn-hlslib/mvau.hpp:167) automatically.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'Matrix_Vector_Activate_Batch<120u, 84u, 1u, 1u, 1u, Slice<ap_uint<4>, 4u>, Slice<ap_uint<4>, 4u>, Identity, ap_uint<4>, ap_uint<4>, FixedPointWeights<1u, ap_int<3>, 1u, 10080u>, ThresholdsActivation<84u, 1u, 15u, ap_int<14>, ap_uint<4>, 0, comp::less_equal<ap_int<14> > >, ap_resource_lut>' (/workspace/finn-hlslib/mvau.hpp:96:46)...14 expression(s) balanced.\n",
      "INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 01:05:12 ; elapsed = 01:05:19 . Memory (MB): peak = 1657.262 ; gain = 1227.754 ; free physical = 1843 ; free virtual = 9707\n",
      "WARNING: [ANALYSIS 214-1] Tool encounters 10081 load/store instructions to analyze which may result in long runtime.\n",
      "/tools/Xilinx/Vivado/2020.1/bin/loader: line 286:   724 Killed                  \"$RDI_PROG\" \"$@\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"/tmp/finn_dev_atchelet/code_gen_ipgen_StreamingDataflowPartition_1_StreamingFCLayer_Batch_3_rssjrv36/vivado_hls.log\",\"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954b36f",
   "metadata": {},
   "source": [
    "### Hardware Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from finn.transformation.fpgadataflow.make_deployment import DeployToPYNQ\n",
    "\n",
    "ip = os.getenv(\"PYNQ_IP\", \"128.131.80.208\")\n",
    "username = os.getenv(\"PYNQ_USERNAME\", \"xilinx\")\n",
    "password = os.getenv(\"PYNQ_PASSWORD\", \"xilinx\")\n",
    "port = os.getenv(\"PYNQ_PORT\", 22)\n",
    "target_dir = os.getenv(\"PYNQ_TARGET_DIR\", \"/home/xilinx/zcu102\")\n",
    "options = \"-o PreferredAuthentications=publickey -o PasswordAuthentication=no\"\n",
    "\n",
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_hw.onnx\")\n",
    "model = model.transform(DeployToPYNQ(ip, port, username, password, target_dir))\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_pynq.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f41d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed35af65ba39e5a16f3dcb5d74a0040cbc997642885eadf410410f5c61311ebb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
