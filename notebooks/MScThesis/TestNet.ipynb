{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5420d782",
   "metadata": {},
   "source": [
    "Small Test Net - Alon Tchelet MSc Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a1db6",
   "metadata": {},
   "source": [
    "# Brevitas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726a95b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36887421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general use libraries\n",
    "import numpy as np\n",
    "\n",
    "# Brevitaas ad PyTorch libraries\n",
    "import torch\n",
    "from torch.nn import Module, ModuleList, Sequential, Conv2d, Linear, ReLU, MaxPool2d, Flatten\n",
    "from brevitas.nn import QuantIdentity, QuantConv2d, QuantLinear, QuantReLU, QuantMaxPool2d\n",
    "from brevitas.inject.defaults import *\n",
    "from brevitas.inject import *\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.bit_width import BitWidthImplType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "from brevitas.core.restrict_val import FloatToIntImplType\n",
    "from brevitas.quant.solver import WeightQuantSolver, ActQuantSolver\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.zero_point import ZeroZeroPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da1024",
   "metadata": {},
   "source": [
    "## Set up network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec3b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyQuant(ExtendedInjector):\n",
    "    bit_width_impl_type = BitWidthImplType.CONST\n",
    "    scaling_impl_type = ScalingImplType.CONST\n",
    "    float_to_int_impl_type = FloatToIntImplType.ROUND\n",
    "    restrict_scaling_type = RestrictValueType.FP\n",
    "    zero_point_impl = ZeroZeroPoint\n",
    "    narrow_range = True\n",
    "    quant_delay_steps = 50\n",
    "    \n",
    "    @value\n",
    "    def quant_type(bit_width):\n",
    "        if bit_width == 1:\n",
    "            return QuantType.BINARY\n",
    "        else:\n",
    "            return QuantType.INT   \n",
    "\n",
    "class MyActQuant(MyQuant, ActQuantSolver):\n",
    "    min_val = 0.0\n",
    "    max_val = 6.0\n",
    "    signed = False \n",
    "    \n",
    "class MyWeightQuant(MyQuant, WeightQuantSolver):\n",
    "    scaling_const = 0.1\n",
    "    signed = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e46664",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLeNet(Module):\n",
    "\n",
    "    # init for CIFAR-10\n",
    "    def __init__(self, weight_bit_width=8, act_bit_width=8):\n",
    "        super(QLeNet, self).__init__()\n",
    "        self.weight_bit_width = int(np.clip(weight_bit_width, 1, 8))\n",
    "        self.act_bit_width = int(np.clip(act_bit_width, 1, 8))\n",
    "\n",
    "        self.conv1 = Sequential(\n",
    "            QuantIdentity(\n",
    "            act_quant=Int8ActPerTensorFloatMinMaxInit,\n",
    "            min_val = -1.0,\n",
    "            max_val = 1.0 - 2.0 ** (-7),\n",
    "            signed = True,\n",
    "            restrict_scaling_type=RestrictValueType.POWER_OF_TWO),\n",
    "            QuantConv2d(3, 6, 5, bias=False, \n",
    "                        weight_quant=MyWeightQuant, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(act_quant=MyActQuant, bit_width=self.act_bit_width),\n",
    "            QuantMaxPool2d(2, 2))\n",
    "        self.conv2 = Sequential(\n",
    "            QuantConv2d(6, 16, 5, bias=False, \n",
    "                        weight_quant=MyWeightQuant, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(act_quant=MyActQuant, bit_width=self.act_bit_width),\n",
    "            QuantMaxPool2d(2, 2))\n",
    "        self.flat = Flatten()\n",
    "        self.fc1 = Sequential(\n",
    "            QuantLinear(400, 120, bias=True,\n",
    "                        weight_quant=MyWeightQuant, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(act_quant=MyActQuant, bit_width=self.act_bit_width))\n",
    "        self.fc2 = Sequential(\n",
    "            QuantLinear(120, 84, bias=True,\n",
    "                        weight_quant=MyWeightQuant, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(act_quant=MyActQuant, bit_width=self.act_bit_width))\n",
    "        self.fc3 = QuantLinear(84, 10, bias=False,\n",
    "                               weight_quant=MyWeightQuant, weight_bit_width=self.weight_bit_width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1b1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "        # init for CIFAR-10\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = Sequential(\n",
    "            Conv2d(3, 6, 5),\n",
    "            ReLU(),\n",
    "            MaxPool2d(2, 2))\n",
    "        self.conv2 = Sequential(\n",
    "            Conv2d(6, 16, 5),\n",
    "            ReLU(),\n",
    "            MaxPool2d(2, 2))\n",
    "        self.flat = Flatten()\n",
    "        self.fc1 = Sequential(\n",
    "            Linear(400, 120),\n",
    "            ReLU())\n",
    "        self.fc2 = Sequential(\n",
    "            Linear(120, 84),\n",
    "            ReLU())\n",
    "        self.fc3 = Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenets = []\n",
    "lenets_names = []\n",
    "\n",
    "# for i in range(2, 9):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i, act_bit_width=i))\n",
    "#     lenets_names.append(f\"lenet_w{i}a{i}\")\n",
    "    \n",
    "# for i in range(2, 8):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i+1, act_bit_width=i))\n",
    "#     lenets_names.append(f\"lenet_w{i+1}a{i}\")\n",
    "\n",
    "# for i in range(1, 8):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i, act_bit_width=i+1))\n",
    "#     lenets_names.append(f\"lenet_w{i}a{i+1}\")\n",
    "    \n",
    "# for i in range(2, 7):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i+2, act_bit_width=i))\n",
    "#     lenets_names.append(f\"lenet_w{i+2}a{i}\")\n",
    "\n",
    "# for i in range(1, 7):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i, act_bit_width=i+2))\n",
    "#     lenets_names.append(f\"lenet_w{i}a{i+2}\")\n",
    "\n",
    "lenet_w3a4 = QLeNet(weight_bit_width=3, act_bit_width=4)\n",
    "lenets.append(lenet_w3a4)\n",
    "lenets_names.append(\"lenet_w3a4\")\n",
    "# lenet_w4a3 = QLeNet(weight_bit_width=4, act_bit_width=3)\n",
    "# lenets.append(lenet_w4a3)\n",
    "# lenets_names.append(\"lenet_w4a3\")\n",
    "# lenet_w2a4 = QLeNet(weight_bit_width=2, act_bit_width=4)\n",
    "# lenets.append(lenet_w2a4)\n",
    "# lenets_names.append(\"lenet_w2a4\")\n",
    "# lenet_w2a3 = QLeNet(weight_bit_width=2, act_bit_width=3)\n",
    "# lenets.append(lenet_w2a3)\n",
    "# lenets_names.append(\"lenet_w2a3\")\n",
    "\n",
    "# lenets.append(LeNet())\n",
    "# lenets_names.append(\"lenet_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741da6b5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a4d3a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af405c1825ad47d1bf7fece1a4fb83bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import SubsetRandomSampler as Sampler\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32\n",
    "split = .9\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                        download=True, transform=transform)\n",
    "validset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "train_len = len(trainset)\n",
    "split = int(split*train_len)\n",
    "idx = list(range(train_len))\n",
    "train_idx, valid_idx = idx[split:], idx[:split]\n",
    "train_samples = Sampler(train_idx)\n",
    "valid_samples = Sampler(valid_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                           sampler=train_samples, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
    "                                          sampler=valid_samples, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e6e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizers = []\n",
    "lr = 0.001\n",
    "epochs = 13\n",
    "\n",
    "for net in lenets:\n",
    "    optimizers.append(optim.Adam(net.parameters(), lr=lr, weight_decay=0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f67922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training for net: lenet_w3a4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] training loss: 2.072654 - valid loss: 1.888182\n",
      "[Epoch: 2] training loss: 1.816645 - valid loss: 1.734186\n",
      "[Epoch: 3] training loss: 1.690531 - valid loss: 1.681997\n",
      "[Epoch: 4] training loss: 1.629322 - valid loss: 1.644902\n",
      "[Epoch: 5] training loss: 1.581870 - valid loss: 1.603250\n",
      "[Epoch: 6] training loss: 1.526722 - valid loss: 1.605791\n",
      "[Epoch: 7] training loss: 1.472588 - valid loss: 1.579410\n",
      "[Epoch: 8] training loss: 1.439207 - valid loss: 1.537854\n",
      "[Epoch: 9] training loss: 1.405831 - valid loss: 1.615846\n",
      "[Epoch: 10] training loss: 1.352492 - valid loss: 1.529345\n",
      "[Epoch: 11] training loss: 1.327599 - valid loss: 1.520218\n",
      "[Epoch: 12] training loss: 1.297085 - valid loss: 1.557670\n",
      "[Epoch: 13] training loss: 1.265748 - valid loss: 1.505930\n",
      "Finished training for net: lenet_w3a4\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for n, net in enumerate(lenets):\n",
    "    print(f\"Started training for net: {lenets_names[n]}\")\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        train_loss = valid_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizers[n].zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizers[n].step()\n",
    "\n",
    "            # print statistics\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= i\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                images, labels = data\n",
    "                outputs = net(images)\n",
    "                vloss = criterion(outputs, labels)\n",
    "                valid_loss += vloss.item()\n",
    "            valid_loss /= i\n",
    "        print(f\"[Epoch: {epoch+1}] training loss: {train_loss:.6f} - valid loss: {valid_loss:.6f}\")\n",
    "        train_loss = valid_loss = 0.0\n",
    "        \n",
    "#         correct = 0\n",
    "#         top3 = 0\n",
    "#         top5 = 0\n",
    "#         total = 0\n",
    "#         with torch.no_grad():\n",
    "#             for data in testloader:\n",
    "#                 images, labels = data\n",
    "#                 outputs = net(images)\n",
    "#                 _, predicted = torch.max(outputs.data, 1)\n",
    "#                 top3_outputs = torch.argsort(outputs.data, 1)[:, -3:]\n",
    "#                 top5_outputs = torch.argsort(outputs.data, 1)[:, -5:]\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "#                 top3 += sum([(out==labels[i]).sum() for i, out in enumerate(top3_outputs)])\n",
    "#                 top5 += sum([(out==labels[i]).sum() for i, out in enumerate(top5_outputs)])\n",
    "#         print(f\"[Epoch: {epoch+1}] Network Accuracy:\\tTop-1: {100 * correct / total : .2f},\\tTop-3: {100 * top3 / total : .2f},\\tTop-5: {100 * top5 / total : .2f}\")\n",
    "            \n",
    "    print(f\"Finished training for net: {lenets_names[n]}\\n\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af6b585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save network\n",
    "for n, net in enumerate(lenets):\n",
    "    path = f\"./{lenets_names[n]}.pth\"\n",
    "    torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4bc72",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d37e65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001,\tBatch size: 32,\tIterations: 13\n",
      "lenet_w3a4 Network Accuracy:\tTop-1:  46.13,\tTop-3:  79.46,\tTop-5:  91.43\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# if you need to load the networks\n",
    "#\n",
    "# lenet_og = QLeNet()\n",
    "# lenet_w8 = QLeNet(weight_bit_width=8)\n",
    "# lenet_w4 = QLeNet(weight_bit_width=4)\n",
    "# lenet_w2 = QLeNet(weight_bit_width=2)\n",
    "# lenet_w8a8 = QLeNet(weight_bit_width=8, act_bit_width=8)\n",
    "# lenet_w4a4 = QLeNet(weight_bit_width=4, act_bit_width=4)\n",
    "# lenet_w2a2 = QLeNet(weight_bit_width=2, act_bit_width=2)\n",
    "# lenets = [lenet_w8a8, lenet_w4a4, lenet_w2a2, lenet_w8, lenet_w4, lenet_w2, lenet_og]\n",
    "# lenets_names = [\"lenet_w8a8\", \"lenet_w4a4\", \"lenet_w2a2\", \"lenet_w8\", \"lenet_w4\", \"lenet_w2\", \"lenet_og\"]\n",
    "# for n, net in enumerate(lenets):\n",
    "#     path = f'./{lenets_names[n]}.pth'\n",
    "#     net.load_state_dict(torch.load(path))\n",
    "#\n",
    "\n",
    "print(f\"Learning rate: {lr},\\tBatch size: {batch_size},\\tIterations: {epochs}\")\n",
    "for n, net in enumerate(lenets):    \n",
    "    correct = 0\n",
    "    top3 = 0\n",
    "    top5 = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            top3_outputs = torch.argsort(outputs.data, 1)[:, -3:]\n",
    "            top5_outputs = torch.argsort(outputs.data, 1)[:, -5:]\n",
    "#             print(f'Predicted: {predicted} - Labels: {labels}\\n')\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            top3 += sum([(out==labels[i]).sum() for i, out in enumerate(top3_outputs)])\n",
    "            top5 += sum([(out==labels[i]).sum() for i, out in enumerate(top5_outputs)])\n",
    "    print(f\"{lenets_names[n]} Network Accuracy:\\tTop-1: {100 * correct / total : .2f},\\tTop-3: {100 * top3 / total : .2f},\\tTop-5: {100 * top5 / total : .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf0f617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenets = []\n",
    "lenets_names = []\n",
    "\n",
    "lenet_w3a4 = QLeNet(weight_bit_width=3, act_bit_width=4)\n",
    "lenets.append(lenet_w3a4)\n",
    "lenets_names.append(\"lenet_w3a4\")\n",
    "# lenet_w4a3 = QLeNet(weight_bit_width=4, act_bit_width=3)\n",
    "# lenets.append(lenet_w4a3)\n",
    "# lenets_names.append(\"lenet_w4a3\")\n",
    "# lenet_w2a4 = QLeNet(weight_bit_width=2, act_bit_width=4)\n",
    "# lenets.append(lenet_w2a4)\n",
    "# lenets_names.append(\"lenet_w2a4\")\n",
    "# lenet_w2a3 = QLeNet(weight_bit_width=2, act_bit_width=3)\n",
    "# lenets.append(lenet_w2a3)\n",
    "# lenets_names.append(\"lenet_w2a3\")\n",
    "\n",
    "# lenets.append(LeNet())\n",
    "# lenets_names.append(\"lenet_base\")\n",
    "\n",
    "for n, net in enumerate(lenets):\n",
    "    path = f'./{lenets_names[n]}.pth'\n",
    "    net.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f90930",
   "metadata": {},
   "source": [
    "# FINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e3506e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b23d4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINN-Brevitas imports\n",
    "import brevitas.onnx as bo\n",
    "\n",
    "# ONNX libraries\n",
    "import onnx\n",
    "import onnx.numpy_helper as nph\n",
    "import onnxruntime as rt\n",
    "\n",
    "# Network display methods - Netron\n",
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "# FINN Network Preperation imports\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from finn.util.pytorch import ToTensor\n",
    "from finn.transformation.merge_onnx_models import MergeONNXModels\n",
    "from finn.core.datatype import DataType\n",
    "from finn.transformation.insert_topk import InsertTopK\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "from finn.transformation.general import RemoveUnusedTensors\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import CreateDataflowPartition\n",
    "from finn.custom_op.registry import getCustomOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268e877",
   "metadata": {},
   "source": [
    "## Brevitas Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca1e2f78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting lenet_w3a4\n"
     ]
    }
   ],
   "source": [
    "for n, net in enumerate(lenets):\n",
    "    print(f\"exporting {lenets_names[n]}\")\n",
    "    onnx_export_path = f\"./onnx/{lenets_names[n]}.onnx\"\n",
    "    bo.export_finn_onnx(net, (1, 3, 32, 32), onnx_export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f54c59",
   "metadata": {},
   "source": [
    "## Network Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfadd0a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# select which network to work with\n",
    "net_n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40dd984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './onnx/lenet_w3a4.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "toDisplay = True\n",
    "# display net through Netron\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990164f",
   "metadata": {},
   "source": [
    "### Tidy ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ec254f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}.onnx\")\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_tidy.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caedc379",
   "metadata": {},
   "source": [
    "### Add Pre/Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d325dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn-base/src/finn/transformation/infer_data_layouts.py:119: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_pre_post.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_tidy.onnx\")\n",
    "\n",
    "# pre-processing\n",
    "in_name = model.graph.input[0].name\n",
    "in_shape = model.get_tensor_shape(in_name)\n",
    "totensor = ToTensor()\n",
    "bo.export_finn_onnx(totensor, in_shape, f\"./onnx/{lenets_names[net_n]}_pre.onnx\")\n",
    "pre_model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_pre.onnx\")\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "in_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(in_name, DataType[\"UINT8\"])\n",
    "\n",
    "# post-processing\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_pre_post.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_pre_post.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c0be1",
   "metadata": {},
   "source": [
    "### Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01258d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_streamline.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_pre_post.onnx\")\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "# model = model.transform(absorb.AbsorbTransposeIntoFlatten())\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_streamline.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_streamline.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed0d00",
   "metadata": {},
   "source": [
    "### convert to HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07b8c6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_hls.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_streamline.onnx\")\n",
    "model = model.transform(to_hls.InferQuantizedStreamingFCLayer())\n",
    "model = model.transform(to_hls.InferThresholdingLayer())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(to_hls.InferConvInpGen())\n",
    "model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(to_hls.InferLabelSelectLayer())\n",
    "model = model.transform(InferDataLayouts())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_hls.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_hls.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6dc7f7",
   "metadata": {},
   "source": [
    "### Create Dataflow Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffe9812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_dataflow_parent.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_hls.onnx\")\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(f\"./onnx/{lenets_names[net_n]}_dataflow_parent.onnx\")\n",
    "\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_dataflow_parent.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8b26034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "parent_model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_dataflow_parent.onnx\")\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "dataflow_model.save(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")\n",
    "\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fcde36",
   "metadata": {},
   "source": [
    "### Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02a59a5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomOp wrapper is of class StreamingFCLayer_Batch #1\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 75\n",
      "MH: ('i', True, 0) = 6\n",
      "resType: ('s', False, 'lut', {'lut', 'dsp', 'auto'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = INT8\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT16\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1, 28, 28]\n",
      "mem_mode: ('s', False, 'const', {'external', 'const', 'decoupled'}) = const\n",
      "ram_style: ('s', False, 'auto', {'distributed', 'ultra', 'block', 'auto'}) = auto\n",
      "ram_style_thresholds: ('s', False, 'auto', {'distributed', 'block', 'auto'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'rtlsim', 'cppsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #2\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 150\n",
      "MH: ('i', True, 0) = 16\n",
      "resType: ('s', False, 'lut', {'lut', 'dsp', 'auto'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT14\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1, 10, 10]\n",
      "mem_mode: ('s', False, 'const', {'external', 'const', 'decoupled'}) = const\n",
      "ram_style: ('s', False, 'auto', {'distributed', 'ultra', 'block', 'auto'}) = auto\n",
      "ram_style_thresholds: ('s', False, 'auto', {'distributed', 'block', 'auto'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'rtlsim', 'cppsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #3\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 400\n",
      "MH: ('i', True, 0) = 120\n",
      "resType: ('s', False, 'lut', {'lut', 'dsp', 'auto'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT16\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1]\n",
      "mem_mode: ('s', False, 'const', {'external', 'const', 'decoupled'}) = const\n",
      "ram_style: ('s', False, 'auto', {'distributed', 'ultra', 'block', 'auto'}) = auto\n",
      "ram_style_thresholds: ('s', False, 'auto', {'distributed', 'block', 'auto'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'rtlsim', 'cppsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #4\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 120\n",
      "MH: ('i', True, 0) = 84\n",
      "resType: ('s', False, 'lut', {'lut', 'dsp', 'auto'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT14\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1]\n",
      "mem_mode: ('s', False, 'const', {'external', 'const', 'decoupled'}) = const\n",
      "ram_style: ('s', False, 'auto', {'distributed', 'ultra', 'block', 'auto'}) = auto\n",
      "ram_style_thresholds: ('s', False, 'auto', {'distributed', 'block', 'auto'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'rtlsim', 'cppsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #5\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 84\n",
      "MH: ('i', True, 0) = 10\n",
      "resType: ('s', False, 'lut', {'lut', 'dsp', 'auto'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = INT16\n",
      "accDataType: ('s', False, 'INT32') = INT16\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 1\n",
      "numInputVectors: ('ints', False, [1]) = [1]\n",
      "mem_mode: ('s', False, 'const', {'external', 'const', 'decoupled'}) = const\n",
      "ram_style: ('s', False, 'auto', {'distributed', 'ultra', 'block', 'auto'}) = auto\n",
      "ram_style_thresholds: ('s', False, 'auto', {'distributed', 'block', 'auto'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'rtlsim', 'cppsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")\n",
    "layers = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")\n",
    "# fc0w = getCustomOp(fc0)\n",
    "# print(\"CustomOp wrapper is of class \" + fc0w.__class__.__name__)\n",
    "for i, layer in enumerate(layers):\n",
    "    temp_op = getCustomOp(layer)\n",
    "    print(f\"CustomOp wrapper is of class StreamingFCLayer_Batch #{i+1}\")\n",
    "    for item in temp_op.get_nodeattr_types():\n",
    "        print(f\"{item}: {temp_op.get_nodeattr_types()[item]} = {temp_op.get_nodeattr(item)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "303225b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_folded.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")\n",
    "\n",
    "# set convolution-input (sliding window) layers folding factors\n",
    "sw_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator\")\n",
    "sw_folding = [3, \n",
    "              2]\n",
    "for layer, simd in zip(sw_layers, sw_folding):\n",
    "    fcl_inst = getCustomOp(layer)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    \n",
    "# set fully-connected layers folding factors\n",
    "fc_layers = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")\n",
    "fc_folding = [\n",
    "    (1, 3, 16),\n",
    "    (2, 2, 16),\n",
    "    (1, 4, 16),\n",
    "    (1, 1, 16),\n",
    "    (1, 1, 16)\n",
    "]\n",
    "for layer, (pe, simd, ififo) in zip(fc_layers, fc_folding):\n",
    "    fcl_inst = getCustomOp(layer)\n",
    "    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    fcl_inst.set_nodeattr(\"inFIFODepth\", ififo)\n",
    "    \n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_folded.onnx\")\n",
    "\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_folded.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df781a4c",
   "metadata": {},
   "source": [
    "## Hardware Build and Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d59e91",
   "metadata": {},
   "source": [
    "### Hardware Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68c809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/transformation/fpgadataflow/floorplan.py:107: UserWarning: 18 nodes have no entry in the provided floorplan, SLR was set to -1\n",
      "  warnings.warn(\n",
      "Process ForkPoolWorker-57:\n",
      "Process ForkPoolWorker-60:\n",
      "Process ForkPoolWorker-59:\n",
      "Process ForkPoolWorker-58:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/workspace/finn/src/finn/transformation/fpgadataflow/hlssynth_ip.py\", line 69, in applyNodeLocal\n",
      "    inst.ipgen_singlenode_code()\n",
      "  File \"/workspace/finn/src/finn/custom_op/fpgadataflow/hlscustomop.py\", line 323, in ipgen_singlenode_code\n",
      "    builder.build(code_gen_dir)\n",
      "  File \"/workspace/finn-base/src/finn/util/hls.py\", line 74, in build\n",
      "    process_compile.communicate()\n",
      "  File \"/opt/conda/lib/python3.8/subprocess.py\", line 1011, in communicate\n",
      "    stdout = self.stdout.read()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "\n",
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_folded.onnx\")\n",
    "model = model.transform(ZynqBuild(platform = \"ZCU102\", period_ns = 10))\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_hw.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954b36f",
   "metadata": {},
   "source": [
    "### Hardware Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from finn.transformation.fpgadataflow.make_deployment import DeployToPYNQ\n",
    "\n",
    "ip = os.getenv(\"PYNQ_IP\", \"128.131.80.208\")\n",
    "username = os.getenv(\"PYNQ_USERNAME\", \"xilinx\")\n",
    "password = os.getenv(\"PYNQ_PASSWORD\", \"xilinx\")\n",
    "port = os.getenv(\"PYNQ_PORT\", 22)\n",
    "target_dir = os.getenv(\"PYNQ_TARGET_DIR\", \"/home/xilinx/zcu102\")\n",
    "options = \"-o PreferredAuthentications=publickey -o PasswordAuthentication=no\"\n",
    "\n",
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_hw.onnx\")\n",
    "model = model.transform(DeployToPYNQ(ip, port, username, password, target_dir))\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_pynq.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f41d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed35af65ba39e5a16f3dcb5d74a0040cbc997642885eadf410410f5c61311ebb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
